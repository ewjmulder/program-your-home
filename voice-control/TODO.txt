Actually, we can do this better!
Voicecommand is just chaining some command line calls to record audio and send it to Google Voice API.
You could do the same in Java, but you could improve on it a lot too!
The key is to use the java Sound API, which uses byte[] Streams for sound data. This gives you
much more fine grained control over the processing. Ideas:
- Leave mic open all the time (if command started)
- Process audio stream and upon hitting a certain volume (treshold) start streaming to google immediately
- Or trigger with for instance 3 claps doing just local peak processing
- Or trigger with button directly on device (abstract away button, just trigger - event bus?)
- When command is spoken, cut off stream after 0.5/1 sec of silence (below treshold) instead of fixed time
- Use supporting Java API's, like:
  - http://www.beadsproject.net/
  - https://code.google.com/p/java-audio-utils/
- NOTE: check to see if it makes sense to record 2 channels, probably not,
  since we don't have stereo mics and it probably is faster / smaller footprint to use 1 channel

Text to speech example, no key required, gives back an mp3*:
http://translate.google.com/translate_tts?tl=nl-nl&q=Dit%20is%20een%20test&ie=UTF-8
Non-official by the way, but hey: http://www.hung-truong.com/blog/2013/04/26/hacking-googles-text-to-speech-api/
BTW: also here, you can start playing as soon as the first bits arrive. Only requirement is that
the network speed is fast enough to get the rest of the data at least at real time speed.
Might be interesting: https://code.google.com/p/java-google-translate-text-to-speech/
* playing mp3 in Java is not trivial, you might need javafx: http://stackoverflow.com/questions/6045384/playing-mp3-and-wav-in-java
  or use a 3rd party lib, like jlayer: http://introcs.cs.princeton.edu/java/faq/mp3/mp3.html
                          or: http://www.morgenstille.at/blog/how-to-play-a-mp3-file-in-java-simple-and-beautiful/

Google Speech API tryout + documentation:
https://github.com/gillesdemey/google-speech-v2

example: curl -X POST --data-binary @/dev/shm/out.flac --user-agent 'Mozilla/5.0' --header 'Content-Type: audio/x-flac; rate=16000;' "https://www.google.com/speech-api/v2/recognize?output=json&lang=$lang&key=AIzaSyBOti4mM-6x9WDnZIjIeyEU21OpBXqWBgw&client=Mozilla/5.0"
(client maybe 'chromium', maybe faster?)

Speech API requires FLAC, which is not bad, since it compresses WAV, but lossless (in contrast to for instance mp3)
We do want to use direct streaming translation (in memory) instead of file based. This can be done
with javaflacencoder: http://javaflacencoder.sourceforge.net/
(NOTE: also try WAV or other stuff uploaded to Google Speech API and find real API description from Google)
Probable usage (TODO: find howto or tutorial or trial/error test):
- create new FlacEncoder
- set stream config to match wave recording
- for test: write to file
- for real: set output stream to be either byte[] which will be uploaded afterwards, or even better:
  as soon as you know the microphone stream should be speech recognized, from that point create a
  pipeline Microphone TargetDataLine -> Audio Input Stream -> Flac Compression Stream -> HTTP Post Output Stream.
  Oh, the beauty of it all... :)
   

Fun other stuff with voice: general knowledge questions to Wolfram Alpha.
There is a key to use with HTTP web requests, API description see:
http://products.wolframalpha.com/docs/WolframAlpha-API-Reference.pdf
Easy for text only: speak -> google speech -> query wolfram alpha -> get result -> google text to speech
Possible fun extra's: reply 'This answer / result contains graphical data / image(s). Do you want to view these on the TV? -> reply with 'yes' or 'no' -> speech api -> do or don't depending on result (or even do a local processing depending on if it best matches 'yes' or 'no' - binary result)

Also possible to use google for simple question/answers:
https://ajax.googleapis.com/ajax/services/search/web?v=1.0&q=<searching for...>
Hmm, maybe not, it does not include the 1 result as an answer
But you could still try to screen grab that, or find a lib that does that, but a lot less clean.




TODO: document and include installation for voicecommand:

http://diyhacking.com/best-voice-recognition-software-for-raspberry-pi/ (follow steps on website)
-- for the lib, choose 'y' only for dependencies and voicecommand

-> also run:
sudo apt-get install libboost-dev libboost-regex-dev youtube-dl axel curl xterm libcurl4-gnutls-dev mpg123 flac sox
not needed: youtube-dl
not working atm: libcurl4-gnutls-dev (voicecommand runs without it)


USB sound card as default device:
http://raspberrypi.stackexchange.com/questions/19705/usb-card-as-my-default-audio-device

Turns out that the OP was thinking along the correct path with his trying
$ sudo nano /etc/modprobe.d/alsa-base.conf
and changing the index from -2 to 0 via adding options snd-usb-audio index=0 to the file. However, this wasn't working.
The correct way to do it is to add options snd-usb-audio index=0 followed by options snd_bcm2835 index=1.
Essentially what doing this is forcing the default sound module (snd_bcm2835) to be disabled while the usb sound module (snd-usb-audio) is enabled.
What I believe was previously happening with just adding options snd-usb-audio index=0 was that the snd-usb-audio module and the snd_bcm2835 were conflicting, with both being enabled.

afterwards: sudo alsa force-reload

LET OP: hierdoor wordt je mic wel plughw:0,0 ipv plughw:1,0 !!

NB: Na inspectie van de sources van voicecommand, lijkt het vooral een slim aan elkaar geknoopt werkje van system commands,
dat prima na te maken moet zijn in Java, dus leuker / beter om dit zelf ter hand te nemen! :)